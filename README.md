# üß† Classifica√ß√£o e Detec√ß√£o Multimodal com COCO

Este projeto implementa modelos para **classifica√ß√£o** e **detec√ß√£o de objetos** utilizando dados multimodais (imagens e legendas) do dataset [COCO](https://cocodataset.org/). Ele explora duas abordagens complementares:

1. **Classifica√ß√£o Multimodal**: combina imagens e legendas usando modelos de deep learning.
2. **Detec√ß√£o de Objetos**: aplica o modelo **Faster R-CNN** para localizar e identificar objetos nas imagens.

## üìÅ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ models/               # Modelos treinados
‚îú‚îÄ‚îÄ results/              # Resultados quantitativos e qualitativos
‚îî‚îÄ‚îÄ README.md             # Este arquivo
```

## üéØ Objetivos

- Treinar um modelo de **classifica√ß√£o multimodal** com representa√ß√µes visuais e textuais.
- Treinar e avaliar um modelo de **detec√ß√£o de objetos** baseado em **Faster R-CNN** com m√©tricas como mAP.
- Testar visualmente previs√µes em imagens reais do COCO.

## üóÇÔ∏è Dataset

- **COCO 2017**:
  - 3k imagens para treino (de ~118k imagens totais)
  - 3 categorias: person, dogs e cars
  - 5 legendas por imagem
  - Anota√ß√µes detalhadas de objetos com bounding boxes
- Link: https://cocodataset.org/#download

## üîß Pr√©-processamento

- **Imagens**: redimensionamento e normaliza√ß√£o.
- **Legendas**: tokeniza√ß√£o com modelos como BERT ou CLIP.
- **Detec√ß√£o**: parsing das anota√ß√µes COCO (bounding boxes e classes).

## üß† Modelos

### Classifica√ß√£o Multimodal

- **Imagem**: ResNet, ViT, CLIP-Vision
- **Texto**: BERT, CLIP-Text
- **Fus√£o**: concatena√ß√£o ou aten√ß√£o cruzada
- **Sa√≠da**: classes via softmax ou sigmoid

### Detec√ß√£o de Objetos

- **Modelo**: [Faster R-CNN](https://arxiv.org/abs/1506.01497)
- **Framework**: PyTorch (torchvision)
- **M√©tricas**: mAP@0.5, mAP@0.5:0.95

### Notebook Principal

1. Instala√ß√£o de depend√™ncias
2. Configura√ß√£o dos caminhos e hiperpar√¢metros
3. Defini√ß√£o da classe `COCODataset`
4. Transforma√ß√µes e augmentations
5. Cria√ß√£o do modelo Faster R-CNN
6. Loop de treinamento e valida√ß√£o
7. Avalia√ß√£o com mAP
8. Visualiza√ß√£o de previs√µes

## üìà Avalia√ß√£o

- Classifica√ß√£o:
  - Acur√°cia, Precision, Recall, F1-score
- Detec√ß√£o:
  - mAP@IoU=0.5
  - mAP@[.5:.95] (intervalo de IoUs)
- Visualiza√ß√£o: bounding boxes desenhados nas imagens com r√≥tulos e scores

## üöÄ Como Rodar

1. Clone o reposit√≥rio:

```bash
git clone https://github.com/vini-mon/COCO_Class-Redes_Neurais
cd COCO_Class-Redes_Neurais
```

2. Baixe os dados COCO (treino e valida√ß√£o)

3. Execute os scripts ou notebooks:

- **Classifica√ß√£o multimodal**: `python notebook.py`

## üí° Aplica√ß√µes

- Sistemas aut√¥nomos de reconhecimento de cenas
- An√°lise de conte√∫do multimodal

## üß™ Tecnologias

- Python 3
- PyTorch, torchvision
- Transformers (HuggingFace)
- OpenCV, matplotlib
- COCO API